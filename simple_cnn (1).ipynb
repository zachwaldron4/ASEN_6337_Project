{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Imports #####\n",
    "\n",
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import multiprocessing\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from albumentations import Compose, VerticalFlip, HorizontalFlip, Rotate, GridDistortion,CenterCrop\n",
    "from copy import deepcopy\n",
    "import cv2\n",
    "import os, glob\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, cohen_kappa_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Grab the data and split into training, validation, and testing datasets #####\n",
    "\n",
    "np.random.seed(10)\n",
    "sample_size = 400\n",
    "\n",
    "test_imgs_folder = '/home/valerie/Remote Sensing Data Analysis/Group Project/test_images/'\n",
    "train_imgs_folder = '/home/valerie/Remote Sensing Data Analysis/Group Project/train_images/'\n",
    "train_df = pd.read_csv('/home/valerie/Remote Sensing Data Analysis/Group Project/train.csv')\n",
    "\n",
    "train_df = train_df[~train_df['EncodedPixels'].isnull()]\n",
    "train_df['Image'] = train_df['Image_Label'].map(lambda x: x.split('_')[0])\n",
    "train_df['Class'] = train_df['Image_Label'].map(lambda x: x.split('_')[1])\n",
    "classes = train_df['Class'].unique()\n",
    "train_df = train_df.groupby('Image')['Class'].agg(set).reset_index()\n",
    "for class_name in classes:\n",
    "    train_df[class_name] = train_df['Class'].map(lambda x: 1 if class_name in x else 0)\n",
    "    \n",
    "train_df = train_df[train_df['Class'].map(len) == 1]   #1348 images like this\n",
    "\n",
    "train_df_v1 = train_df.sample(sample_size)\n",
    "train_df_v2 = train_df.sample(sample_size)\n",
    "img_2_ohe_vector = {img:vec for img, vec in zip(train_df['Image'], train_df.iloc[:, 2:].values)}\n",
    "\n",
    "\n",
    "train_imgs, val_imgs = train_test_split(train_df_v1['Image'].values, \n",
    "                                        test_size=0.2, \n",
    "                                        stratify=train_df_v1['Class'].map(lambda x: str(sorted(list(x)))), # sorting present classes in lexicographical order, just to be sure\n",
    "                                        random_state=43)\n",
    "\n",
    "train_imgs, test_imgs = train_test_split(train_df_v2['Image'].values, \n",
    "                                        test_size=0.2, \n",
    "                                        stratify=train_df_v2['Class'].map(lambda x: str(sorted(list(x)))), # sorting present classes in lexicographical order, just to be sure\n",
    "                                        random_state=43)\n",
    "\n",
    "#print(train_df['Class'][4])\n",
    "#print(len(train_df['Class'][4]))\n",
    "#print(len(train_df['Class']))\n",
    "\n",
    "train_df_v1.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Create DataGenerator class to organize the data arrays #####\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, images_list=None, folder_imgs=train_imgs_folder, \n",
    "                 batch_size=1, shuffle=True, augmentation=None,\n",
    "                 resized_height=224, resized_width=224, num_channels=3):\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.augmentation = augmentation\n",
    "        if images_list is None:\n",
    "            self.images_list = os.listdir(folder_imgs)\n",
    "        else:\n",
    "            self.images_list = deepcopy(images_list)\n",
    "        self.folder_imgs = folder_imgs\n",
    "        self.len = len(self.images_list) // self.batch_size\n",
    "        self.resized_height = resized_height\n",
    "        self.resized_width = resized_width\n",
    "        self.num_channels = num_channels\n",
    "        self.num_classes = 4\n",
    "        self.is_test = not 'train' in folder_imgs\n",
    "        if not shuffle and not self.is_test:\n",
    "            self.labels = [img_2_ohe_vector[img] for img in self.images_list[:self.len*self.batch_size]]\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.len\n",
    "    \n",
    "    def on_epoch_start(self):\n",
    "        if self.shuffle:\n",
    "            random.shuffle(self.images_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        current_batch = self.images_list[idx * self.batch_size: (idx + 1) * self.batch_size]\n",
    "        X = np.empty((self.batch_size, self.resized_height, self.resized_width, self.num_channels))\n",
    "        y = np.empty((self.batch_size, self.num_classes))\n",
    "\n",
    "\n",
    "        for i, image_name in enumerate(current_batch):\n",
    "            path = os.path.join(self.folder_imgs, image_name)\n",
    "            #try:\n",
    "            img = cv2.resize(cv2.imread(path), (self.resized_height, self.resized_width)).astype(np.float32)\n",
    "            #  print(img.shape)\n",
    "            #except:\n",
    "              # if it fails, who cares there are more images\n",
    "            #  img = np.zeros([self.resized_height, self.resized_width, 3], dtype=np.float32)\n",
    "            #  print('error')  \n",
    "              #self.__getitem__(idx+1)  \n",
    "\n",
    "\n",
    "            if not self.augmentation is None:\n",
    "                print(img.shape)\n",
    "                augmented = self.augmentation(image=img)\n",
    "                img = augmented['image']\n",
    "                print(img.shape)\n",
    "            X[i, :, :, :] = img#/255.0\n",
    "            if not self.is_test:\n",
    "                y[i, :] = img_2_ohe_vector[image_name]\n",
    "        return X, y\n",
    "\n",
    "    def get_labels(self):\n",
    "        if self.shuffle:\n",
    "            images_current = self.images_list[:self.len*self.batch_size]\n",
    "            labels = [img_2_ohe_vector[img] for img in images_current]\n",
    "        else:\n",
    "            labels = self.labels\n",
    "        return np.array(labels)\n",
    "\n",
    "albumentations_train = Compose([VerticalFlip(), HorizontalFlip(), Rotate(limit=20), GridDistortion()], p=1)\n",
    "\n",
    "data_generator_train = DataGenerator(train_imgs, augmentation=None)\n",
    "data_generator_val = DataGenerator(val_imgs, augmentation=None)\n",
    "data_generator_test = DataGenerator(test_imgs, augmentation=None)\n",
    "\n",
    "\n",
    "#data_generator_test.__getitem__(1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Get data arrays to work with #####\n",
    "\n",
    "X_train = np.zeros((int(sample_size*0.8), 224, 224, 3))\n",
    "Y_train = np.zeros((int(sample_size*0.8), 4))\n",
    "X_val = np.zeros((int(sample_size*0.2), 224, 224, 3))\n",
    "Y_val = np.zeros((int(sample_size*0.2), 4))\n",
    "X_test = np.zeros((int(sample_size*0.2), 224, 224, 3))\n",
    "Y_test = np.zeros((int(sample_size*0.2), 4))\n",
    "\n",
    "for i in range(0, int(sample_size*0.8)):     #####batch size is 32\n",
    "    X_train[i,:,:,:] = data_generator_train.__getitem__(i)[0]  #shape(0.8*sample_size, 224, 224, 3)\n",
    "    Y_train[i,:] = data_generator_train.__getitem__(i)[1]      #shape(0.8*sample_size, 4)\n",
    "    \n",
    "for i in range(0, int(sample_size*0.2)):\n",
    "    X_val[i,:,:,:] = data_generator_val.__getitem__(i)[0]  #shape(0.2*sample_size, 224, 224, 3)\n",
    "    Y_val[i,:] = data_generator_val.__getitem__(i)[1]      #shape(0.2*sample_size, 4)\n",
    "    X_test[i,:,:,:] = data_generator_test.__getitem__(i)[0]  #shape(0.2*sample_size, 224, 224, 3)\n",
    "    Y_test[i,:] = data_generator_test.__getitem__(i)[1]      #shape(0.2*sample_size, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Y_test\n",
    "#60 // 32\n",
    "\n",
    "#data_generator_test.__getitem__(1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Normalize the image data #####\n",
    "X_train = X_train.astype('float32')\n",
    "X_val = X_val.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "#X_train /= 255\n",
    "#X_val /= 255\n",
    "#X_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Build a simple CNN model #####\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=X_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Compile the CNN model #####\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Fit the CNN model #####\n",
    "\n",
    "score_history = model.fit(X_train, Y_train, batch_size=32, epochs=8,\n",
    "              validation_data=(X_val, Y_val), shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "##### Predict test data #####\n",
    "Y_pred = model.predict(X_test)\n",
    "Y_pred = (Y_pred > 0.5)\n",
    "#print(Y_pred)\n",
    "#print(Y_test)\n",
    "\n",
    "Y_pred_labels = np.zeros(len(Y_pred))\n",
    "Y_test_labels = np.zeros(len(Y_test))\n",
    "for i in range(len(Y_pred)):\n",
    "    idx_pred = np.where(Y_pred[i]==True)[0][0]\n",
    "    Y_pred_labels[i] = idx_pred + 1\n",
    "    idx_test = np.where(Y_test[i]==1)[0][0]\n",
    "    Y_test_labels[i] = idx_test + 1\n",
    "\n",
    "cm = confusion_matrix(Y_test_labels, Y_pred_labels)\n",
    "print(cm)\n",
    "\n",
    "#assess classification results\n",
    "#confusion matrix\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "mat = confusion_matrix(Y_test_labels, Y_pred_labels)\n",
    "\n",
    "f, ax = plt.subplots(1,1,figsize=(12,8))\n",
    "g = sns.heatmap(mat, annot=True, square=True, fmt=\"d\", cbar=False, xticklabels=[1,2,3,4], yticklabels=[1,2,3,4], ax = ax)\n",
    "g.set_xlabel('Predicted')\n",
    "g.set_ylabel('True')\n",
    "g.set_title('$p_0$ = %.3f, $\\kappa$ = %.3f' % (accuracy_score(Y_test_labels, Y_pred_labels), cohen_kappa_score(Y_test_labels, Y_pred_labels)))\n",
    "plt.show()\n",
    "\n",
    "\n",
    "epochs = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "loss_hist = score_history.history['loss']\n",
    "accuracy_hist = score_history.history['accuracy']\n",
    "val_loss_hist = score_history.history['val_loss']\n",
    "val_accuracy_hist = score_history.history['val_accuracy']\n",
    "\n",
    "#plot model accuracy\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(epochs, accuracy_hist, label='Accuracy')\n",
    "plt.plot(epochs, val_accuracy_hist, label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "#plot model loss\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(epochs, loss_hist, label='Loss')\n",
    "plt.plot(epochs, val_loss_hist, label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Get CNN model scores #####\n",
    "\n",
    "scores = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#### try with sigmoid activation functions\n",
    "\n",
    "##### Build a simple CNN model #####\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=X_train.shape[1:]))\n",
    "model.add(Activation('sigmoid'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "##### Compile the CNN model #####\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "##### Fit the CNN model #####\n",
    "score_history = model.fit(X_train, Y_train, batch_size=32, epochs=8,\n",
    "              validation_data=(X_val, Y_val), shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "##### Predict test data #####\n",
    "Y_pred = model.predict(X_test)\n",
    "Y_pred = (Y_pred > 0.5)\n",
    "#print(Y_pred)\n",
    "#print(Y_test)\n",
    "\n",
    "Y_pred_labels = np.zeros(len(Y_pred))\n",
    "Y_test_labels = np.zeros(len(Y_test))\n",
    "for i in range(len(Y_pred)):\n",
    "    idx_pred = np.where(Y_pred[i]==True)[0][0]\n",
    "    Y_pred_labels[i] = idx_pred + 1\n",
    "    idx_test = np.where(Y_test[i]==1)[0][0]\n",
    "    Y_test_labels[i] = idx_test + 1\n",
    "\n",
    "\n",
    "#assess classification results\n",
    "#confusion matrix\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "mat = confusion_matrix(Y_test_labels, Y_pred_labels)\n",
    "\n",
    "f, ax = plt.subplots(1,1,figsize=(12,8))\n",
    "g = sns.heatmap(mat, annot=True, square=True, fmt=\"d\", cbar=False, xticklabels=[1,2,3,4], yticklabels=[1,2,3,4], ax = ax)\n",
    "g.set_xlabel('Predicted')\n",
    "g.set_ylabel('True')\n",
    "g.set_title('$p_0$ = %.3f, $\\kappa$ = %.3f' % (accuracy_score(Y_test_labels, Y_pred_labels), cohen_kappa_score(Y_test_labels, Y_pred_labels)))\n",
    "plt.show()\n",
    "\n",
    "epochs = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "loss_hist = score_history.history['loss']\n",
    "accuracy_hist = score_history.history['accuracy']\n",
    "val_loss_hist = score_history.history['val_loss']\n",
    "val_accuracy_hist = score_history.history['val_accuracy']\n",
    "\n",
    "#plot model accuracy\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(epochs, accuracy_hist, label='Accuracy')\n",
    "plt.plot(epochs, val_accuracy_hist, label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "#plot model loss\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(epochs, loss_hist, label='Loss')\n",
    "plt.plot(epochs, val_loss_hist, label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "##### Get CNN model scores #####\n",
    "scores = model.evaluate(X_test, Y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#### try with scaled data\n",
    "\n",
    "##### Normalize the image data #####\n",
    "X_train = X_train.astype('float32')\n",
    "X_val = X_val.astype('float32')\n",
    "X_test = X_test.astype('float32')\n",
    "X_train_scaled = X_train / 255\n",
    "X_val_scaled = X_val / 255\n",
    "X_test_scaled = X_test / 255\n",
    "\n",
    "\n",
    "##### Build a simple CNN model #####\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=X_train.shape[1:]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "##### Compile the CNN model #####\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "##### Fit the CNN model #####\n",
    "score_history = model.fit(X_train_scaled, Y_train, batch_size=32, epochs=8,\n",
    "              validation_data=(X_val_scaled, Y_val), shuffle=True)\n",
    "\n",
    "\n",
    "\n",
    "##### Predict test data #####\n",
    "Y_pred = model.predict(X_test_scaled)\n",
    "print(np.shape(Y_pred))\n",
    "for i in range(len(Y_pred)):\n",
    "    j = np.argmax(Y_pred[i,:])\n",
    "    Y_pred[i,j] = 1\n",
    "print(Y_pred)\n",
    "#print(Y_test)\n",
    "\n",
    "Y_pred_labels = np.zeros(len(Y_pred))\n",
    "Y_test_labels = np.zeros(len(Y_test))\n",
    "for i in range(len(Y_pred)):\n",
    "    idx_pred = np.where(Y_pred[i]==1)[0][0]\n",
    "    Y_pred_labels[i] = idx_pred +1\n",
    "    idx_test = np.where(Y_test[i]==1)[0][0]\n",
    "    Y_test_labels[i] = idx_test + 1\n",
    "\n",
    "\n",
    "#assess classification results\n",
    "#confusion matrix\n",
    "plt.rcParams.update({'font.size': 22})\n",
    "mat = confusion_matrix(Y_test_labels, Y_pred_labels)\n",
    "\n",
    "f, ax = plt.subplots(1,1,figsize=(12,8))\n",
    "g = sns.heatmap(mat, annot=True, square=True, fmt=\"d\", cbar=False, xticklabels=[1,2,3,4], yticklabels=[1,2,3,4], ax = ax)\n",
    "g.set_xlabel('Predicted')\n",
    "g.set_ylabel('True')\n",
    "g.set_title('$p_0$ = %.3f, $\\kappa$ = %.3f' % (accuracy_score(Y_test_labels, Y_pred_labels), cohen_kappa_score(Y_test_labels, Y_pred_labels)))\n",
    "plt.show()\n",
    "\n",
    "epochs = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "loss_hist = score_history.history['loss']\n",
    "accuracy_hist = score_history.history['accuracy']\n",
    "val_loss_hist = score_history.history['val_loss']\n",
    "val_accuracy_hist = score_history.history['val_accuracy']\n",
    "\n",
    "#plot model accuracy\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(epochs, accuracy_hist, label='Accuracy')\n",
    "plt.plot(epochs, val_accuracy_hist, label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "#plot model loss\n",
    "plt.figure(figsize=(12,8))\n",
    "plt.plot(epochs, loss_hist, label='Loss')\n",
    "plt.plot(epochs, val_loss_hist, label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(loc='best')\n",
    "plt.show()\n",
    "\n",
    "##### Get CNN model scores #####\n",
    "scores = model.evaluate(X_test_scaled, Y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
